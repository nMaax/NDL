{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641e9285",
   "metadata": {},
   "source": [
    "## 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a988f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.linalg import null_space\n",
    "from scipy import sparse\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Reproducibility seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce93a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES = 500          \n",
    "K_NEIGHBORS = 4        \n",
    "BETA = 0.3             \n",
    "RHO = 0.7              \n",
    "WEEKS = 15             \n",
    "N_SIMULATIONS = 100    \n",
    "INITIAL_INFECTED = 10  \n",
    "\n",
    "\n",
    "SUSCEPTIBLE = 0\n",
    "INFECTED = 1\n",
    "RECOVERED = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_regular_graph(n, k):\n",
    "    rows = []\n",
    "    cols = []\n",
    "\n",
    "    # For each node i, neighbors are ±1, ±2 ... up to k/2\n",
    "    half_k = k // 2\n",
    "\n",
    "    for i in range(n):\n",
    "        for offset in range(1, half_k + 1):\n",
    "            # right neighbor (i + offset)\n",
    "            neighbor_r = (i + offset) % n\n",
    "            rows.append(i)\n",
    "            cols.append(neighbor_r)\n",
    "\n",
    "            # left neighbor (i - offset)\n",
    "            neighbor_l = (i - offset) % n\n",
    "            rows.append(i)\n",
    "            cols.append(neighbor_l)\n",
    "\n",
    "    data = np.ones(len(rows))\n",
    "    adj_matrix = sparse.csr_matrix((data, (rows, cols)), shape=(n, n))\n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43713189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(adj_matrix, n_nodes, weeks, beta, rho, initial_infected, initial_infected_choice='random'):\n",
    "    # at the beginning all nodes are susceptible -> everyone is S = 0\n",
    "    states = np.zeros(n_nodes, dtype=int)\n",
    "\n",
    "    if initial_infected_choice == 'random':\n",
    "        initial_infected_indices = np.random.choice(n_nodes, initial_infected, replace=False)\n",
    "    elif initial_infected_choice == 'cluster':\n",
    "        start_node = np.random.randint(0, n_nodes)\n",
    "        initial_infected_indices = [(start_node + i) % n_nodes for i in range(initial_infected)]\n",
    "\n",
    "    states[initial_infected_indices] = INFECTED\n",
    "\n",
    "    # i = 0 for initial state, i = 1..15 for next weeks\n",
    "    history_S = np.zeros(weeks + 1)\n",
    "    history_I = np.zeros(weeks + 1)\n",
    "    history_R = np.zeros(weeks + 1)\n",
    "    new_infections_hist = np.zeros(weeks + 1)\n",
    "\n",
    "    # initial state (t=0)\n",
    "    history_S[0] = np.sum(states == SUSCEPTIBLE)\n",
    "    history_I[0] = np.sum(states == INFECTED)\n",
    "    history_R[0] = np.sum(states == RECOVERED)\n",
    "    new_infections_hist[0] = initial_infected\n",
    "\n",
    "    for t in range(weeks):\n",
    "        # current infected nodes\n",
    "        infected_mask = (states == INFECTED)\n",
    "\n",
    "        # number of infected neighbors for each node\n",
    "        m = adj_matrix.dot(infected_mask.astype(int))\n",
    "\n",
    "        # P(S -> I) = 1 - (1 - beta)^m\n",
    "        prob_infection = 1 - (1 - beta) ** m\n",
    "\n",
    "        random_vals = np.random.rand(n_nodes)\n",
    "\n",
    "        newly_infected_mask = (states == SUSCEPTIBLE) & (random_vals < prob_infection)\n",
    "\n",
    "        # P(I -> R) = rho \n",
    "        random_vals_rec = np.random.rand(n_nodes)\n",
    "        newly_recovered_mask = (states == INFECTED) & (random_vals_rec < rho)\n",
    "\n",
    "        # states update synchronously given the discrete time nature of the model\n",
    "        states[newly_infected_mask] = INFECTED\n",
    "        states[newly_recovered_mask] = RECOVERED\n",
    "\n",
    "        count_S = np.sum(states == SUSCEPTIBLE)\n",
    "        count_I = np.sum(states == INFECTED)\n",
    "        count_R = np.sum(states == RECOVERED)\n",
    "        count_New_I = np.sum(newly_infected_mask)\n",
    "\n",
    "        history_S[t+1] = count_S\n",
    "        history_I[t+1] = count_I\n",
    "        history_R[t+1] = count_R\n",
    "        new_infections_hist[t+1] = count_New_I\n",
    "\n",
    "    return history_S, history_I, history_R, new_infections_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86911a1a",
   "metadata": {},
   "source": [
    "### Simulation with random initial infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289888a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = create_k_regular_graph(N_NODES, K_NEIGHBORS)\n",
    "\n",
    "total_S = np.zeros(WEEKS + 1)\n",
    "total_I = np.zeros(WEEKS + 1)\n",
    "total_R = np.zeros(WEEKS + 1)\n",
    "total_new_I = np.zeros(WEEKS + 1)\n",
    "\n",
    "\n",
    "for sim in range(N_SIMULATIONS):\n",
    "    s, i, r, new_i = run_simulation(adj_matrix, N_NODES, WEEKS, BETA, RHO, INITIAL_INFECTED)\n",
    "    total_S += s\n",
    "    total_I += i\n",
    "    total_R += r\n",
    "    total_new_I += new_i\n",
    "\n",
    "avg_S = total_S / N_SIMULATIONS\n",
    "avg_I = total_I / N_SIMULATIONS\n",
    "avg_R = total_R / N_SIMULATIONS\n",
    "avg_new_I = total_new_I / N_SIMULATIONS\n",
    "\n",
    "weeks_range = np.arange(WEEKS + 1)\n",
    "\n",
    "def plot_epidemic(weeks, avg_S, avg_I, avg_R, avg_new_I):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(weeks, avg_new_I, marker='o', color='red', linestyle='-', label='Newly Infected (Average)')\n",
    "    plt.title('New infected weekly average')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Number of new infected')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(weeks, avg_S, marker='o', label='S', color='blue')\n",
    "    plt.plot(weeks, avg_I, marker='o', label='I', color='orange')\n",
    "    plt.plot(weeks, avg_R, marker='o', label='R', color='green')\n",
    "    plt.title('Total average individuals S, I, R each week')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Total number of individuals')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_epidemic(weeks_range, avg_S, avg_I, avg_R, avg_new_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32b102",
   "metadata": {},
   "source": [
    "even trying different values of $\\beta$ and $\\rho$\n",
    "\n",
    "- with $\\beta \\cdot k < \\rho$: no peak\n",
    "- with $\\beta \\cdot k \\ge \\rho$: peak but then the topology of the net still avoids the epidemic infecting all the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BETA = [0.1, 0.3, 0.5, 0.9]\n",
    "RHO = [0.1, 0.3, 0.7, 0.9]\n",
    "WEEKS = 100\n",
    "weeks_range = np.arange(WEEKS + 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14))\n",
    "\n",
    "colors = plt.cm.jet(np.linspace(0, 1, len(BETA) * len(RHO))) \n",
    "c_idx = 0\n",
    "\n",
    "for beta in BETA:\n",
    "    for rho in RHO:\n",
    "        \n",
    "        total_S = np.zeros(WEEKS + 1)\n",
    "        total_I = np.zeros(WEEKS + 1)\n",
    "        total_R = np.zeros(WEEKS + 1)\n",
    "        total_new_I = np.zeros(WEEKS + 1)\n",
    "\n",
    "        for sim in range(N_SIMULATIONS):\n",
    "            s, i, r, new_i = run_simulation(adj_matrix, N_NODES, WEEKS, beta, rho, INITIAL_INFECTED)\n",
    "            total_S += s\n",
    "            total_I += i\n",
    "            total_R += r\n",
    "            total_new_I += new_i\n",
    "\n",
    "        avg_S = total_S / N_SIMULATIONS\n",
    "        avg_I = total_I / N_SIMULATIONS\n",
    "        avg_R = total_R / N_SIMULATIONS\n",
    "        avg_new_I = total_new_I / N_SIMULATIONS\n",
    "\n",
    "        label_sim = f'BETA={beta}, RHO={rho}'\n",
    "        \n",
    "        ax1.plot(weeks_range, avg_new_I, \n",
    "                 linestyle='-', \n",
    "                 label=label_sim, \n",
    "                 color=colors[c_idx])\n",
    "        \n",
    "        # just plot avg_I for readability\n",
    "        ax2.plot(weeks_range, avg_I, \n",
    "                 linestyle='-', \n",
    "                 label=f'Infected ({label_sim})',\n",
    "                 color=colors[c_idx])\n",
    "        \n",
    "        c_idx += 1\n",
    "\n",
    "ax1.set_title('Comparison: Weekly average new infected')\n",
    "ax1.set_xlabel('Week')\n",
    "ax1.set_ylabel('Number of new infected')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "\n",
    "ax2.set_title('Comparison: Average total infected individuals each week')\n",
    "ax2.set_xlabel('Week')\n",
    "ax2.set_ylabel('Total active infected individuals')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af61bc",
   "metadata": {},
   "source": [
    "### Simulation with initial infected taken from a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80da734",
   "metadata": {},
   "source": [
    "Choosing 10 neighbor nodes as initial infected, the epidemic dies out even faster because the initial infected shares the same suscepitble neighbors saturating the infection locally.\n",
    "\n",
    "In a cluster, many of the links of infected nodes point to other already infected nodes within the group. These links are \"wasted\" because they cannot transmit the infection to new susceptible nodes. In the random configuration, however, almost all the links of the 10 infected nodes point to susceptible nodes, maximizing the probability of immediate expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6319112",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES = 500          \n",
    "K_NEIGHBORS = 4        \n",
    "BETA = 0.3             \n",
    "RHO = 0.7              \n",
    "WEEKS = 15             \n",
    "N_SIMULATIONS = 100    \n",
    "INITIAL_INFECTED = 10  \n",
    "\n",
    "adj_matrix = create_k_regular_graph(N_NODES, K_NEIGHBORS)\n",
    "\n",
    "total_S = np.zeros(WEEKS + 1)\n",
    "total_I = np.zeros(WEEKS + 1)\n",
    "total_R = np.zeros(WEEKS + 1)\n",
    "total_new_I = np.zeros(WEEKS + 1)\n",
    "\n",
    "\n",
    "for sim in range(N_SIMULATIONS):\n",
    "    s, i, r, new_i = run_simulation(adj_matrix, N_NODES, WEEKS, BETA, RHO, INITIAL_INFECTED, initial_infected_choice='cluster')\n",
    "    total_S += s\n",
    "    total_I += i\n",
    "    total_R += r\n",
    "    total_new_I += new_i\n",
    "\n",
    "avg_S = total_S / N_SIMULATIONS\n",
    "avg_I = total_I / N_SIMULATIONS\n",
    "avg_R = total_R / N_SIMULATIONS\n",
    "avg_new_I = total_new_I / N_SIMULATIONS\n",
    "\n",
    "weeks_range = np.arange(WEEKS + 1)\n",
    "plot_epidemic(weeks_range, avg_S, avg_I, avg_R, avg_new_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f095a0",
   "metadata": {},
   "source": [
    "### Simulation with different values of $k$ and initial infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e677d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "BETA = 0.3\n",
    "RHO = 0.7\n",
    "INITIAL_INFECTED = [10, 50, 100]\n",
    "K_NEIGHBORS = [4, 10, 20]\n",
    "WEEKS = 100\n",
    "weeks_range = np.arange(WEEKS + 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14))\n",
    "\n",
    "colors = plt.cm.jet(np.linspace(0, 1, len(INITIAL_INFECTED) * len(K_NEIGHBORS))) \n",
    "c_idx = 0\n",
    "\n",
    "for initial_infected in INITIAL_INFECTED:\n",
    "    for k in K_NEIGHBORS:\n",
    "        adj_matrix = create_k_regular_graph(N_NODES, k)\n",
    "        \n",
    "        total_S = np.zeros(WEEKS + 1)\n",
    "        total_I = np.zeros(WEEKS + 1)\n",
    "        total_R = np.zeros(WEEKS + 1)\n",
    "        total_new_I = np.zeros(WEEKS + 1)\n",
    "\n",
    "        for sim in range(N_SIMULATIONS):\n",
    "            s, i, r, new_i = run_simulation(adj_matrix, N_NODES, WEEKS, BETA, RHO, initial_infected)\n",
    "            total_S += s\n",
    "            total_I += i\n",
    "            total_R += r\n",
    "            total_new_I += new_i\n",
    "\n",
    "        avg_S = total_S / N_SIMULATIONS\n",
    "        avg_I = total_I / N_SIMULATIONS\n",
    "        avg_R = total_R / N_SIMULATIONS\n",
    "        avg_new_I = total_new_I / N_SIMULATIONS\n",
    "\n",
    "        label_sim = f'Initial Infected={initial_infected}, K={k}'\n",
    "        \n",
    "        ax1.plot(weeks_range, avg_new_I, \n",
    "                 linestyle='-', \n",
    "                 label=label_sim, \n",
    "                 color=colors[c_idx])\n",
    "        \n",
    "        # just plot avg_I for readability\n",
    "        ax2.plot(weeks_range, avg_I, \n",
    "                 linestyle='-', \n",
    "                 label=f'Infected ({label_sim})',\n",
    "                 color=colors[c_idx])\n",
    "        \n",
    "        c_idx += 1\n",
    "\n",
    "ax1.set_title('Comparison: Weekly average new infected')\n",
    "ax1.set_xlabel('Week')\n",
    "ax1.set_ylabel('Number of new infected')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "\n",
    "ax2.set_title('Comparison: Average total infected individuals each week')\n",
    "ax2.set_xlabel('Week')\n",
    "ax2.set_ylabel('Total active infected individuals')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfddf1de",
   "metadata": {},
   "source": [
    "## 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_PA_graph(n_total, k):\n",
    "    # INITIALIZATION (Time t=1)\n",
    "    # Start with a complete graph (clique) of k+1 nodes\n",
    "    # This ensures the initial average degree is exactly k.\n",
    "    m0 = k + 1\n",
    "    G = nx.complete_graph(m0)\n",
    "    \n",
    "    # Parameters for the alternating mechanism\n",
    "    is_k_odd = (k % 2 != 0)\n",
    "    c_floor = int(np.floor(k / 2))\n",
    "    c_ceil = int(np.ceil(k / 2))\n",
    "    \n",
    "    # GROWTH (Time t >= 2)\n",
    "    # We add nodes one by one from index m0 up to n_total - 1\n",
    "    for new_node in range(m0, n_total):\n",
    "        \n",
    "        # Determine c (number of edges to add)\n",
    "        if is_k_odd:\n",
    "            # Alternate between floor and ceil\n",
    "            # We use the node index to decide (even or odd step)\n",
    "            if new_node % 2 == 0:\n",
    "                c = c_floor\n",
    "            else:\n",
    "                c = c_ceil\n",
    "        else:\n",
    "            # If k is even, c is always k/2\n",
    "            c = int(k / 2)\n",
    "            \n",
    "        # Get the list of existing nodes\n",
    "        existing_nodes = np.array(G.nodes())\n",
    "        \n",
    "        # Get degrees of all existing nodes (w_i(t-1))\n",
    "        # Note: G.degree() returns (node, degree) tuples, we just need the degrees\n",
    "        degrees = np.array([G.degree(n) for n in existing_nodes])\n",
    "        \n",
    "        # Calculate the sum of degrees (Denominator of the formula)\n",
    "        degree_sum = degrees.sum()\n",
    "        \n",
    "        # Calculate Probabilities\n",
    "        # P(i) = w_i / sum(w)\n",
    "        probabilities = degrees / degree_sum\n",
    "        \n",
    "        # Select 'c' targets based on these probabilities\n",
    "        # replace=False ensures we do not add multiple links to the same node\n",
    "        targets = np.random.choice(existing_nodes, size=c, replace=False, p=probabilities)\n",
    "        \n",
    "        # Add the new node and the edges\n",
    "        G.add_node(new_node)\n",
    "        for target in targets:\n",
    "            G.add_edge(new_node, target)\n",
    "            \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38616277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out graph generation and visualize\n",
    "G = generate_PA_graph(100, 4)\n",
    "\n",
    "pos = nx.spring_layout(G, k=0.15, iterations=20, seed=42) \n",
    "\n",
    "d = dict(G.degree)\n",
    "node_sizes = [v * 10 for v in d.values()] # Scale based on degree for visualization\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='red', alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5, edge_color='black')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 2000     # Final number of nodes\n",
    "K_TARGET = 8 # Target average degree (even number for default case)\n",
    "\n",
    "# Generate Graph\n",
    "G_pa = generate_PA_graph(N, K_TARGET)\n",
    "\n",
    "# Compute Actual Average Degree\n",
    "degrees = [d for n, d in G_pa.degree()]\n",
    "k_actual = np.mean(degrees)\n",
    "\n",
    "print(f\"Target Average Degree: {K_TARGET}\")\n",
    "print(f\"Actual Average Degree: {k_actual:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Degree Distribution\n",
    "degree_sequence = [d for _, d in G_pa.degree()]\n",
    "max_deg = max(degree_sequence)\n",
    "plt.hist(degree_sequence, bins=range(0, max_deg + 2), align='left')\n",
    "plt.axvline(x=K_TARGET, color='red', linestyle=':', label='Target k')\n",
    "plt.axvline(x=k_actual, color='green', linestyle=':', label='Actual k')\n",
    "plt.title(f\"Degree Distribution (Histogram) for Target k={K_TARGET}\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b38ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = 2000     # Final number of nodes\n",
    "K_TARGET = 5 # Target average degree (Odd number to test the tricky case)\n",
    "\n",
    "# Generate Graph\n",
    "G_pa = generate_PA_graph(N, K_TARGET)\n",
    "\n",
    "# Compute Actual Average Degree\n",
    "degrees = [d for n, d in G_pa.degree()]\n",
    "k_actual = np.mean(degrees)\n",
    "\n",
    "print(f\"Target Average Degree: {K_TARGET}\")\n",
    "print(f\"Actual Average Degree: {k_actual:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Degree Distribution\n",
    "degree_sequence = [d for _, d in G_pa.degree()]\n",
    "max_deg = max(degree_sequence)\n",
    "plt.hist(degree_sequence, bins=range(0, max_deg + 2), align='left')\n",
    "plt.axvline(x=K_TARGET, color='red', linestyle=':', label='Target k')\n",
    "plt.axvline(x=k_actual, color='green', linestyle=':', label='Actual k')\n",
    "plt.title(f\"Degree Distribution (Histogram) for Target k={K_TARGET}\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5c1a3",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES =  500          # Graph size\n",
    "K_TARGET = 6            # Target average degree\n",
    "BETA = 0.3              # Infection rate\n",
    "RHO = 0.7               # Recovery rate\n",
    "WEEKS = 15              # Duration of simulation\n",
    "N_SIMULATIONS = 100     # Number of runs to average\n",
    "INITIAL_INFECTED = 10   # Number of initially infected nodes\n",
    "\n",
    "print(f\"Generating PA graph with N={N_NODES} and K={K_TARGET}...\")\n",
    "G_pa = generate_PA_graph(N_NODES, K_TARGET)\n",
    "adj_matrix = nx.to_scipy_sparse_array(G_pa, format='csr')\n",
    "\n",
    "print(\"Running simulations...\")\n",
    "total_S = np.zeros(WEEKS + 1)\n",
    "total_I = np.zeros(WEEKS + 1)\n",
    "total_R = np.zeros(WEEKS + 1)\n",
    "total_new_I = np.zeros(WEEKS + 1)\n",
    "\n",
    "for sim in range(N_SIMULATIONS):\n",
    "    s, i, r, new_i = run_simulation(\n",
    "        adj_matrix, \n",
    "        N_NODES, \n",
    "        WEEKS, \n",
    "        BETA, \n",
    "        RHO, \n",
    "        INITIAL_INFECTED, \n",
    "        initial_infected_choice='random'\n",
    "    )\n",
    "    total_S += s\n",
    "    total_I += i\n",
    "    total_R += r\n",
    "    total_new_I += new_i\n",
    "\n",
    "avg_S = total_S / N_SIMULATIONS\n",
    "avg_I = total_I / N_SIMULATIONS\n",
    "avg_R = total_R / N_SIMULATIONS\n",
    "avg_new_I = total_new_I / N_SIMULATIONS\n",
    "\n",
    "weeks_range = np.arange(WEEKS + 1)\n",
    "\n",
    "def plot_epidemic_results(weeks, avg_S, avg_I, avg_R, avg_new_I):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Plot New Infections\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(weeks, avg_new_I, marker='o', color='red', linestyle='-', label='Newly Infected (Avg)')\n",
    "    plt.title(f'PA Graph (N={N_NODES}, k={K_TARGET}): New infected weekly average')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Number of new infected')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot SIR States\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(weeks, avg_S, marker='o', label='Susceptible', color='blue')\n",
    "    plt.plot(weeks, avg_I, marker='o', label='Infected', color='orange')\n",
    "    plt.plot(weeks, avg_R, marker='o', label='Recovered', color='green')\n",
    "    plt.title('Total average individuals S, I, R each week')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Total number of individuals')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_epidemic_results(weeks_range, avg_S, avg_I, avg_R, avg_new_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef188bf4",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ae68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES =  500          # Graph size\n",
    "K_TARGET = 6            # Target average degree\n",
    "BETA = 0.3              # Infection rate\n",
    "RHO = 0.7               # Recovery rate\n",
    "WEEKS = 15              # Duration of simulation\n",
    "N_SIMULATIONS = 100     # Number of runs to average\n",
    "INITIAL_INFECTED = 10   # Number of initially infected nodes\n",
    "\n",
    "VACCINATED = 3          # New state\n",
    "VACCINATION_SCHEDULE_PCT = [0, 5, 15, 25, 35, 45, 55, 60, 60, 60, 60, 60, 60, 60, 60]   # Cumulative percentage of population vaccinated each week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_with_vaccination(adj_matrix, n_nodes, weeks, beta, rho, initial_infected, vacc_schedule_pct, initial_infected_choice='random'):\n",
    "    # at the beginning all nodes are susceptible -> everyone is S = 0\n",
    "    states = np.zeros(n_nodes, dtype=int)\n",
    "    \n",
    "    if initial_infected_choice == 'random':\n",
    "        initial_infected_indices = np.random.choice(n_nodes, initial_infected, replace=False)\n",
    "    elif initial_infected_choice == 'cluster':\n",
    "        start_node = np.random.randint(0, n_nodes)\n",
    "        initial_infected_indices = [(start_node + i) % n_nodes for i in range(initial_infected)]\n",
    "\n",
    "    states[initial_infected_indices] = INFECTED\n",
    "    \n",
    "    # i = 0 for initial state, i = 1..15 for next weeks\n",
    "    history_S = np.zeros(weeks + 1)\n",
    "    history_I = np.zeros(weeks + 1)\n",
    "    history_R = np.zeros(weeks + 1)\n",
    "    history_V = np.zeros(weeks + 1)\n",
    "    \n",
    "    new_infections_hist = np.zeros(weeks + 1)\n",
    "    new_vaccinations_hist = np.zeros(weeks + 1)\n",
    "    \n",
    "    # initial state (t=0)\n",
    "    history_S[0] = np.sum(states == SUSCEPTIBLE)\n",
    "    history_I[0] = np.sum(states == INFECTED)\n",
    "    history_R[0] = np.sum(states == RECOVERED)\n",
    "    history_V[0] = np.sum(states == VACCINATED)\n",
    "    new_infections_hist[0] = initial_infected\n",
    "    new_vaccinations_hist[0] = 0    # no vaccination happens in the initial state\n",
    "    \n",
    "\n",
    "    for t in range(weeks):\n",
    "        # Compute  percentual of people that could be vaccinated during this week\n",
    "        target_pct = vacc_schedule_pct[t]\n",
    "        \n",
    "        prev_pct = vacc_schedule_pct[t-1] if t > 0 else 0\n",
    "        \n",
    "        delta_pct = target_pct - prev_pct\n",
    "        \n",
    "        num_newly_vaccinated = 0\n",
    "        \n",
    "        if delta_pct > 0:\n",
    "            num_to_vaccinate = int((delta_pct / 100.0) * n_nodes)\n",
    "            \n",
    "            # candidates who are not already vaccinated\n",
    "            candidate_mask = (states != VACCINATED)\n",
    "            candidate_indices = np.where(candidate_mask)[0]\n",
    "            \n",
    "            num_actual = min(num_to_vaccinate, len(candidate_indices))\n",
    "            \n",
    "            if num_actual > 0:\n",
    "                chosen_indices = np.random.choice(candidate_indices, num_actual, replace=False)\n",
    "                \n",
    "                # Apply the Vaccination\n",
    "                states[chosen_indices] = VACCINATED\n",
    "                num_newly_vaccinated = num_actual\n",
    "\n",
    " \n",
    "        # currently infected nodes\n",
    "        infected_mask = (states == INFECTED)\n",
    "        \n",
    "        # number of infected neighbors for each node\n",
    "        m = adj_matrix.dot(infected_mask.astype(int))\n",
    "        \n",
    "        # P(S -> I) = 1 - (1 - beta)^m\n",
    "        prob_infection = 1 - (1 - beta) ** m\n",
    "        \n",
    "        random_vals = np.random.rand(n_nodes)\n",
    "        \n",
    "        newly_infected_mask = (states == SUSCEPTIBLE) & (random_vals < prob_infection)\n",
    "        \n",
    "\n",
    "        # P(I -> R) = rho \n",
    "        random_vals_rec = np.random.rand(n_nodes)\n",
    "        newly_recovered_mask = (states == INFECTED) & (random_vals_rec < rho)\n",
    "        \n",
    "        # states update synchronously given the discrete time nature of the model\n",
    "        states[newly_infected_mask] = INFECTED\n",
    "        states[newly_recovered_mask] = RECOVERED\n",
    "        \n",
    "        history_S[t+1] = np.sum(states == SUSCEPTIBLE)\n",
    "        history_I[t+1] = np.sum(states == INFECTED)\n",
    "        history_R[t+1] = np.sum(states == RECOVERED)\n",
    "        history_V[t+1] = np.sum(states == VACCINATED)\n",
    "        \n",
    "        new_infections_hist[t+1] = np.sum(newly_infected_mask)\n",
    "        new_vaccinations_hist[t+1] = num_newly_vaccinated\n",
    "        \n",
    "    return history_S, history_I, history_R, history_V, new_infections_hist, new_vaccinations_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generating PA graph with N={N_NODES} and K={K_TARGET}...\")\n",
    "G_pa_vacc = generate_PA_graph(N_NODES, K_TARGET)\n",
    "adj_matrix_vacc = nx.to_scipy_sparse_array(G_pa_vacc, format='csr')\n",
    "\n",
    "print(\"Running simulations with vaccination...\")\n",
    "total_S = np.zeros(WEEKS + 1)\n",
    "total_I = np.zeros(WEEKS + 1)\n",
    "total_R = np.zeros(WEEKS + 1)\n",
    "total_V = np.zeros(WEEKS + 1)\n",
    "total_new_I = np.zeros(WEEKS + 1)\n",
    "total_new_V = np.zeros(WEEKS + 1)\n",
    "\n",
    "for sim in range(N_SIMULATIONS):\n",
    "    s, i, r, v, new_i, new_v = run_simulation_with_vaccination(\n",
    "        adj_matrix_vacc, \n",
    "        N_NODES, \n",
    "        WEEKS, \n",
    "        BETA, \n",
    "        RHO, \n",
    "        INITIAL_INFECTED,\n",
    "        VACCINATION_SCHEDULE_PCT,\n",
    "        initial_infected_choice='random'\n",
    "    )\n",
    "    total_S += s\n",
    "    total_I += i\n",
    "    total_R += r\n",
    "    total_V += v\n",
    "    total_new_I += new_i\n",
    "    total_new_V += new_v\n",
    "\n",
    "avg_S = total_S / N_SIMULATIONS\n",
    "avg_I = total_I / N_SIMULATIONS\n",
    "avg_R = total_R / N_SIMULATIONS\n",
    "avg_V = total_V / N_SIMULATIONS\n",
    "avg_new_I = total_new_I / N_SIMULATIONS\n",
    "avg_new_V = total_new_V / N_SIMULATIONS\n",
    "\n",
    "weeks_range = np.arange(WEEKS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d168e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epidemic_with_vaccination_results(weeks_range, avg_S, avg_I, avg_R, avg_V, avg_new_I, avg_new_V):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    # Plot New Infections and New Vaccinations\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(weeks_range, avg_new_I, marker='o', color='red', linestyle='-', label='Newly Infected (Avg)')\n",
    "    plt.plot(weeks_range, avg_new_V, marker='x', color='purple', linestyle='--', label='Newly Vaccinated (Avg)')\n",
    "    plt.title(f'Pandemic with Vaccination (PA Graph, k={K_TARGET}): Weekly New Events')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Number of individuals')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot SIRV States\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(weeks_range, avg_S, marker='o', label='Susceptible', color='blue')\n",
    "    plt.plot(weeks_range, avg_I, marker='o', label='Infected', color='orange')\n",
    "    plt.plot(weeks_range, avg_R, marker='o', label='Recovered', color='green')\n",
    "    plt.plot(weeks_range, avg_V, marker='o', label='Vaccinated', color='purple')\n",
    "    plt.title('Total average individuals S, I, R, V each week')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Total number of individuals')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_epidemic_with_vaccination_results(weeks_range, avg_S, avg_I, avg_R, avg_V, avg_new_I, avg_new_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10292416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati del testo\n",
    "VACC = [5, 9, 16, 24, 32, 40, 47, 54, 59, 60, 60, 60, 60, 60, 60]   # 15 settimane\n",
    "I0 = np.array([1, 1, 3, 5, 9, 17, 32, 32, 17, 5, 2, 1, 0, 0, 0, 0], dtype=float)  # len=16\n",
    "\n",
    "NODES = 934\n",
    "WEEKS = 15\n",
    "N = 10 \n",
    "\n",
    "initial_infected = int(I0[0])\n",
    "\n",
    "assert len(VACC) == WEEKS\n",
    "assert len(I0) == WEEKS + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe19627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_avg_I_and_states(k, beta, rho):\n",
    "\n",
    "    # Generate PA graph\n",
    "    G = generate_PA_graph(NODES, int(k))\n",
    "    adj = nx.to_scipy_sparse_array(G, format='csr')\n",
    "\n",
    "    # Prepare variables for results\n",
    "    total_new_I = np.zeros(WEEKS + 1)\n",
    "    total_S = np.zeros(WEEKS + 1)\n",
    "    total_I = np.zeros(WEEKS+ 1)\n",
    "    total_R = np.zeros(WEEKS + 1)\n",
    "    total_V = np.zeros(WEEKS + 1)\n",
    "\n",
    "    # Simulate N times and average results\n",
    "    for _ in range(N):\n",
    "        S, I, R, V, new_I, new_V = run_simulation_with_vaccination(\n",
    "            adj, NODES, WEEKS, beta, rho, initial_infected, VACC,\n",
    "            initial_infected_choice='random'\n",
    "        )\n",
    "        total_S += S\n",
    "        total_I += I\n",
    "        total_R += R\n",
    "        total_V += V\n",
    "        total_new_I += new_I\n",
    "\n",
    "    avg_S = total_S / N\n",
    "    avg_I = total_I / N\n",
    "    avg_R = total_R / N\n",
    "    avg_V = total_V / N\n",
    "    avg_new_I = total_new_I / N  \n",
    "\n",
    "    rmse = np.sqrt((1/15) * np.sum((avg_new_I[1:] - I0[1:])**2))\n",
    "\n",
    "    return rmse, avg_new_I, avg_S, avg_I, avg_R, avg_V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_h1n1(k0=10, beta0=0.3, rho0=0.6, dk=1, db=0.1, dr=0.1):\n",
    "\n",
    "    # Round initial parameters\n",
    "    beta0 = round(beta0, 3)\n",
    "    rho0  = round(rho0, 3)\n",
    "\n",
    "    while True:\n",
    "        # Generate the neighborhood\n",
    "        k_space = [k0 - dk, k0, k0 + dk]\n",
    "        b_space = [round(beta0 - db, 3), beta0, round(beta0 + db, 3)]\n",
    "        r_space = [round(rho0 - dr, 3),  rho0, round(rho0 + dr, 3)]\n",
    "\n",
    "        best_local = None  # (rmse, k, beta, rho, avg_new_I, avg_S, avg_I, avg_R, avg_V)\n",
    "\n",
    "        # Explore each combination in the neighborhood\n",
    "        for k in k_space:\n",
    "            if k < 2:\n",
    "                continue\n",
    "            for beta in b_space:\n",
    "                if beta < 0 or beta > 1:\n",
    "                    continue\n",
    "                for rho in r_space:\n",
    "                    if rho < 0 or rho > 1:\n",
    "                        continue\n",
    "\n",
    "                    # Run simulation and compute RMSE\n",
    "                    rmse, avg_new_I, avg_S, avg_I, avg_R, avg_V = simulate_avg_I_and_states(\n",
    "                        int(k), float(beta), float(rho)\n",
    "                    )\n",
    "\n",
    "                    cand = (\n",
    "                        rmse,\n",
    "                        int(k),\n",
    "                        round(beta, 3),\n",
    "                        round(rho, 3),\n",
    "                        avg_new_I, avg_S, avg_I, avg_R, avg_V\n",
    "                    )\n",
    "\n",
    "                    # Find the best among the current neighbors\n",
    "                    if (best_local is None) or (cand[0] < best_local[0]):\n",
    "                        best_local = cand\n",
    "\n",
    "        # Extract the best parameters of this step\n",
    "        rmse_best, k_best, beta_best, rho_best = best_local[:4]\n",
    "\n",
    "        print(\n",
    "            f\"Best local configuration found, with RMSE={rmse_best:.4f} \"\n",
    "            f\"(k={k_best}, beta={beta_best:.3f}, rho={rho_best:.3f})\"\n",
    "        )\n",
    "\n",
    "        # Convergence check\n",
    "        if (k_best == k0) and (beta_best == beta0) and (rho_best == rho0):\n",
    "            print(\"Convergence reached. Returning best parameters.\")\n",
    "            return best_local\n",
    "\n",
    "        # Updated neighborhood center\n",
    "        k0, beta0, rho0 = k_best, beta_best, rho_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fit_h1n1(k0=10, beta0=0.3, rho0=0.6, dk=1, db=0.1, dr=0.1)\n",
    "\n",
    "rmse_best, k_best, beta_best, rho_best, avg_new_I, avg_S, avg_I, avg_R, avg_V = best\n",
    "\n",
    "print(\"\\n=== BEST PARAMETERS (global minimum found) ===\")\n",
    "print(f\"k    = {k_best}\")\n",
    "print(f\"beta = {beta_best}\")\n",
    "print(f\"rho  = {rho_best}\")\n",
    "print(f\"RMSE = {rmse_best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580cf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Simulation results vs true data\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, WEEKS + 1), avg_new_I[1:], marker='o', linestyle='-', label='Model: avg_new_I')\n",
    "plt.plot(range(1, WEEKS + 1), I0[1:],        marker='s', linestyle='--', label='True: I0')\n",
    "plt.title(f'Weekly newly infected: model vs true (k={k_best}, beta={beta_best:.3f}, rho={rho_best:.3f})')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Newly infected individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# S, I, R, V totals\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(0, WEEKS + 1), avg_S, marker='o', label='Susceptible (S)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_I, marker='o', label='Infected (I)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_R, marker='o', label='Recovered (R)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_V, marker='o', label='Vaccinated (V)')\n",
    "plt.title('Model totals each week: S, I, R, V')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566e18a",
   "metadata": {},
   "source": [
    "## 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c66712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_h1n1_refine_adaptive_steps(\n",
    "    k0=10, beta0=0.3, rho0=0.6,\n",
    "    dk=1, db=0.1, dr=0.1,\n",
    "    min_dk=1, min_db=0.005, min_dr=0.005,\n",
    "    shrink=0.5,\n",
    "    max_iters=200,\n",
    "    round_p=6\n",
    "):\n",
    "    \n",
    "    def quantize(k, b, r):\n",
    "        return (int(k), round(float(b), round_p), round(float(r), round_p))\n",
    "\n",
    "    k0, beta0, rho0 = quantize(k0, beta0, rho0)\n",
    "\n",
    "    dk = int(dk)\n",
    "    db = float(db)\n",
    "    dr = float(dr)\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "\n",
    "        # Generate neighborhood for current center\n",
    "        k_space = [k0 - dk, k0, k0 + dk]\n",
    "        b_space = [beta0 - db, beta0, beta0 + db]\n",
    "        r_space = [rho0  - dr, rho0,  rho0  + dr]\n",
    "\n",
    "        best_local = None\n",
    "\n",
    "        for k in k_space:\n",
    "            if k < 2: continue\n",
    "            k = int(k)\n",
    "\n",
    "            for beta in b_space:\n",
    "                if not (0 <= beta <= 1): continue\n",
    "                beta = round(float(beta), round_p)\n",
    "\n",
    "                for rho in r_space:\n",
    "                    if not (0 <= rho <= 1): continue\n",
    "                    rho = round(float(rho), round_p)\n",
    "\n",
    "                    # Run simulation\n",
    "                    sim_result = simulate_avg_I_and_states(k, beta, rho)\n",
    "                    current_rmse = sim_result[0]\n",
    "\n",
    "                    # If this is the best so far in the neighborhood, store it and clean up local variable\n",
    "                    if (best_local is None) or (current_rmse < best_local[0]):\n",
    "                        best_local = (\n",
    "                            current_rmse, k, beta, rho,\n",
    "                            sim_result[1], sim_result[2], sim_result[3], sim_result[4], sim_result[5]\n",
    "                        )\n",
    "                    del sim_result\n",
    "\n",
    "        rmse_best, k_best, beta_best, rho_best = best_local[0], best_local[1], best_local[2], best_local[3]\n",
    "\n",
    "        print(\n",
    "            f\"Iter {iteration}: Best RMSE={rmse_best:.4f} at (k={k_best}, b={beta_best:.3f}, r={rho_best:.3f}) \"\n",
    "            f\"| steps: dk={dk}, db={db:.4f}, dr={dr:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Cleanup garbage collector, to free memory from local variables\n",
    "        gc.collect()\n",
    "\n",
    "        # Check if we are stuck\n",
    "        stuck = (k_best == k0) and (beta_best == beta0) and (rho_best == rho0)\n",
    "        if not stuck:\n",
    "            k0, beta0, rho0 = k_best, beta_best, rho_best\n",
    "            continue\n",
    "\n",
    "        # If all steps are at their minimum, we have converged.\n",
    "        if (dk <= min_dk) and (db <= min_db) and (dr <= min_dr):\n",
    "            print(\"Convergence reached: minimum step sizes achieved.\")\n",
    "            return best_local\n",
    "\n",
    "        # Else, shrink steps\n",
    "        new_dk = max(min_dk, int(dk * shrink))\n",
    "        if new_dk < min_dk: new_dk = min_dk\n",
    "\n",
    "        new_db = max(min_db, round(db * shrink, round_p))\n",
    "        new_dr = max(min_dr, round(dr * shrink, round_p))\n",
    "\n",
    "        if (new_dk == dk) and (new_db == db) and (new_dr == dr):\n",
    "            print(\"Steps cannot be shrunk further. Stopping.\")\n",
    "            return best_local\n",
    "\n",
    "        dk, db, dr = new_dk, new_db, new_dr\n",
    "        print(f\" -> Stuck! Shrinking steps as: dk={dk}, db={db:.6f}, dr={dr:.6f}\")\n",
    "\n",
    "    print(\"Reached maximum iterations. Stopping.\")\n",
    "    return best_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ce75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fit_h1n1_refine_adaptive_steps(\n",
    "    k0=10, beta0=0.3, rho0=0.6,\n",
    "    dk=3, db=0.1, dr=0.1,\n",
    "    min_dk=1, min_db=0.01, min_dr=0.01\n",
    ")\n",
    "\n",
    "rmse_best, k_best, beta_best, rho_best, avg_new_I, avg_S, avg_I, avg_R, avg_V = best\n",
    "print(\"\\n=== BEST PARAMETERS (global minimum found) ===\")\n",
    "print(f\"k = {k_best}\")\n",
    "print(f\"beta = {beta_best}\")\n",
    "print(f\"rho = {rho_best}\")\n",
    "print(f\"RMSE = {rmse_best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62172084",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Simulation results vs true data\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, WEEKS + 1), avg_new_I[1:], marker='o', linestyle='-', label='Model: avg_new_I')\n",
    "plt.plot(range(1, WEEKS + 1), I0[1:],        marker='s', linestyle='--', label='True: I0')\n",
    "plt.title(f'Weekly newly infected: model vs true (k={k_best}, beta={beta_best:.3f}, rho={rho_best:.3f})')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Newly infected individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# S, I, R, V totals\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(0, WEEKS + 1), avg_S, marker='o', label='Susceptible (S)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_I, marker='o', label='Infected (I)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_R, marker='o', label='Recovered (R)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_V, marker='o', label='Vaccinated (V)')\n",
    "plt.title('Model totals each week: S, I, R, V')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177d361",
   "metadata": {},
   "source": [
    "#### Small World model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_small_world_graph(n, k, p=0.05):\n",
    "    # n: number of nodes\n",
    "    # k: average degree neighbors\n",
    "    # p: rewiring probability\n",
    "\n",
    "    # Watts-Strogatz requires k to be even\n",
    "    if k % 2 != 0:\n",
    "        k += 1 \n",
    "\n",
    "    G = nx.watts_strogatz_graph(n, k, p)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96768905",
   "metadata": {},
   "source": [
    "#### Holme-Kim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5733c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_holme_kim(n_nodes, m_edges, p_triangle=0.5):\n",
    "    # n_nodes: number of nodes\n",
    "    # m_edges: number of edges to attach from a new node to existing nodes\n",
    "    # p_triangle: probability of adding a triangle after adding a random edge\n",
    "\n",
    "    G = nx.powerlaw_cluster_graph(n=n_nodes, m=m_edges, p=p_triangle)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ad7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out graph generation and visualize\n",
    "PA_G = generate_PA_graph(100, 4)\n",
    "WS_G = generate_small_world_graph(100, 4, p=0.1)\n",
    "HK_G = generate_holme_kim(100, 2, p_triangle=0.5)\n",
    "\n",
    "pa_pos = nx.spring_layout(PA_G, k=0.15, iterations=20, seed=42)\n",
    "ws_pos = nx.spring_layout(WS_G, k=0.15, iterations=20, seed=42)\n",
    "hk_pos = nx.spring_layout(HK_G, k=0.15, iterations=20, seed=42)\n",
    "\n",
    "pa_d = dict(PA_G.degree)\n",
    "ws_d = dict(WS_G.degree)\n",
    "hk_d = dict(HK_G.degree)\n",
    "pa_node_sizes = [v * 10 for v in pa_d.values()] # Scale based on degree for visualization\n",
    "ws_node_sizes = [v * 10 for v in ws_d.values()] # Scale based on degree for visualization\n",
    "hk_node_sizes = [v * 10 for v in hk_d.values()] # Scale based on degree for visualization\n",
    "\n",
    "# Preferential Attachment Graph\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "nx.draw_networkx_nodes(PA_G, pa_pos, node_size=pa_node_sizes, node_color='red', alpha=0.8)\n",
    "nx.draw_networkx_edges(PA_G, pa_pos, alpha=0.5, edge_color='black')\n",
    "plt.title(\"Preferential Attachment Graph\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Watts-Strogatz Graph\n",
    "plt.subplot(1, 3, 2)\n",
    "nx.draw_networkx_nodes(WS_G, ws_pos, node_size=ws_node_sizes, node_color='blue', alpha=0.8)\n",
    "nx.draw_networkx_edges(WS_G, ws_pos, alpha=0.5, edge_color='black')\n",
    "plt.title(\"Watts-Strogatz Graph\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Holme-Kim Graph\n",
    "plt.subplot(1, 3, 3)\n",
    "nx.draw_networkx_nodes(HK_G, hk_pos, node_size=hk_node_sizes, node_color='green', alpha=0.8)\n",
    "nx.draw_networkx_edges(HK_G, hk_pos, alpha=0.5, edge_color='black')\n",
    "plt.title(\"Holme-Kim Graph\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e04ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generic_adaptive_steps(\n",
    "    simulate_func,        # Simulation function to use\n",
    "    initial_params,       # Initial parameter values [k0, beta0, rho0, ...]\n",
    "    initial_steps,        # Initial step values [dk, db, dr, ...]\n",
    "    min_steps,            # Minimal step values [min_dk, min_db, ...]\n",
    "    bounds,               # Bounds for each param: [(min1, max1), (min2, max2), ...]\n",
    "    param_types,          # Types for each param: [int, float, float, ...]\n",
    "    shrink=0.5,\n",
    "    max_iters=200,\n",
    "    round_p=6\n",
    "):\n",
    "\n",
    "    # Helper function to clean and validate parameters\n",
    "    def clean_param(val, p_type, bound):\n",
    "        # Casting and rounding\n",
    "        if p_type is int:\n",
    "            val = int(round(val))\n",
    "        else:\n",
    "            val = round(float(val), round_p)\n",
    "\n",
    "        # Check bounds\n",
    "        if bound is not None:\n",
    "            min_b, max_b = bound\n",
    "            if min_b is not None and val < min_b: return None # Scarta\n",
    "            if max_b is not None and val > max_b: return None # Scarta\n",
    "        return val\n",
    "\n",
    "    # Ensure inputs are lists and check lengths\n",
    "    current_params = list(initial_params)\n",
    "    current_steps = list(initial_steps)\n",
    "    n_params = len(current_params)\n",
    "\n",
    "    assert len(current_steps) == n_params\n",
    "    assert len(min_steps) == n_params\n",
    "    assert len(bounds) == n_params\n",
    "    assert len(param_types) == n_params\n",
    "\n",
    "    # Initial cleaning of starting parameters\n",
    "    for i in range(n_params):\n",
    "        cleaned = clean_param(current_params[i], param_types[i], bounds[i])\n",
    "        if cleaned is None:\n",
    "            raise ValueError(f\"Initial parameter {i} out of bounds: {current_params[i]}\")\n",
    "        current_params[i] = cleaned\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "\n",
    "        # Generate search axes for each parameter\n",
    "        search_axes = []\n",
    "        for i in range(n_params):\n",
    "            val = current_params[i]\n",
    "            step = current_steps[i]\n",
    "\n",
    "            # Generate raw candidates\n",
    "            raw_candidates = [val - step, val, val + step]\n",
    "\n",
    "            # Clean and validate candidates\n",
    "            valid_candidates = []\n",
    "            for cand in raw_candidates:\n",
    "                c = clean_param(cand, param_types[i], bounds[i])\n",
    "                if c is not None:\n",
    "                    valid_candidates.append(c)\n",
    "\n",
    "            # Remove duplicates and sort\n",
    "            search_axes.append(sorted(list(set(valid_candidates))))\n",
    "\n",
    "        best_local = None \n",
    "\n",
    "        # Explore the cartesian product of all parameter candidates\n",
    "        for params_tuple in itertools.product(*search_axes):\n",
    "\n",
    "            # Run simulation with the current parameter set\n",
    "            sim_result = simulate_func(*params_tuple)\n",
    "\n",
    "            # Extract RMSE\n",
    "            current_rmse = sim_result[0]\n",
    "\n",
    "            # Check if best in local neighborhood\n",
    "            if (best_local is None) or (current_rmse < best_local[0]):\n",
    "                best_local = (current_rmse, params_tuple) + sim_result[1:]\n",
    "\n",
    "            # Clean up local variable\n",
    "            del sim_result\n",
    "\n",
    "        # Extract best parameters from local search so far\n",
    "        rmse_best = best_local[0]\n",
    "        best_params_tuple = best_local[1]\n",
    "\n",
    "        # Log current best\n",
    "        param_str = \", \".join([f\"{p}\" if isinstance(p, int) else f\"{p:.3f}\" for p in best_params_tuple])\n",
    "        step_str = \", \".join([f\"{s}\" if isinstance(s, int) else f\"{s:.4f}\" for s in current_steps])\n",
    "        print(f\"Iter {iteration}: Best RMSE={rmse_best:.4f} at ({param_str}) | steps: [{step_str}]\")\n",
    "\n",
    "        # Cleanup garbage collector\n",
    "        gc.collect()\n",
    "\n",
    "        # Check if stuck\n",
    "        is_stuck = (list(best_params_tuple) == current_params)\n",
    "        if not is_stuck:\n",
    "            current_params = list(best_params_tuple)\n",
    "            continue\n",
    "\n",
    "        # Check if all steps are at minimum\n",
    "        all_min = True\n",
    "        for i in range(n_params):\n",
    "            if current_steps[i] > min_steps[i]:\n",
    "                all_min = False\n",
    "                break\n",
    "\n",
    "        if all_min:\n",
    "            print(\"Convergence reached: minimum step sizes achieved.\")\n",
    "            return best_local\n",
    "\n",
    "        # Compute new shrunk steps\n",
    "        new_steps = []\n",
    "        unchanged_steps = True\n",
    "\n",
    "        for i in range(n_params):\n",
    "            old_s = current_steps[i]\n",
    "            s_shrunk = old_s * shrink\n",
    "\n",
    "            if param_types[i] is int:\n",
    "                new_s = max(min_steps[i], int(s_shrunk))\n",
    "            else:\n",
    "                new_s = max(min_steps[i], round(s_shrunk, round_p))\n",
    "\n",
    "            new_steps.append(new_s)\n",
    "            if new_s != old_s:\n",
    "                unchanged_steps = False\n",
    "\n",
    "        if unchanged_steps:\n",
    "            print(\"Convergence reached: steps cannot be shrunk further.\")\n",
    "            return best_local\n",
    "\n",
    "        current_steps = new_steps\n",
    "        step_debug = \", \".join([f\"{s:.6f}\" for s in current_steps])\n",
    "        print(f\" -> Stuck! Shrinking steps: {step_debug}\")\n",
    "\n",
    "    print(\"Converged: maximum iterations reached.\")\n",
    "    return best_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(k, beta, rho, p, graph_generation_func=generate_small_world_graph, n_simulations=N):\n",
    "    G = graph_generation_func(NODES, int(k), p)\n",
    "    adj = nx.to_scipy_sparse_array(G, format='csr')\n",
    "\n",
    "    total_new_I = np.zeros(WEEKS + 1)\n",
    "    total_S = np.zeros(WEEKS + 1)\n",
    "    total_I = np.zeros(WEEKS+ 1)\n",
    "    total_R = np.zeros(WEEKS + 1)\n",
    "    total_V = np.zeros(WEEKS + 1)\n",
    "\n",
    "    for _ in range(n_simulations):\n",
    "        S, I, R, V, new_I, new_V = run_simulation_with_vaccination(\n",
    "            adj, NODES, WEEKS, beta, rho, initial_infected, VACC,\n",
    "            initial_infected_choice='random'\n",
    "        )\n",
    "        total_S += S\n",
    "        total_I += I\n",
    "        total_R += R\n",
    "        total_V += V\n",
    "        total_new_I += new_I\n",
    "\n",
    "    avg_S = total_S / n_simulations\n",
    "    avg_I = total_I / n_simulations\n",
    "    avg_R = total_R / n_simulations\n",
    "    avg_V = total_V / n_simulations\n",
    "    avg_new_I = total_new_I / n_simulations\n",
    "\n",
    "    rmse = np.sqrt((1/15) * np.sum((avg_new_I[1:] - I0[1:])**2))\n",
    "\n",
    "    return rmse, avg_new_I, avg_S, avg_I, avg_R, avg_V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6849fff4",
   "metadata": {},
   "source": [
    "#### Small World params estimation and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b926379",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_init = [10,  0.3, 0.6, 0.1]          # k0, beta0, rho0, p\n",
    "steps_init  = [3,   0.1, 0.1, 0.01]         # dk, db, dr\n",
    "min_steps   = [1,   0.01, 0.01, 0.005]      # min_dk, min_db, min_dr\n",
    "p_types     = [int, float, float, float]    # types\n",
    "p_bounds    = [ \n",
    "    # Bounds: k >= 2, 0 <= beta <= 1, 0 <= rho <= 1\n",
    "    (2, None), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0)\n",
    "]\n",
    "\n",
    "best_result = fit_generic_adaptive_steps(\n",
    "    simulate_func=simulate,\n",
    "    initial_params=params_init,\n",
    "    initial_steps=steps_init,\n",
    "    min_steps=min_steps,\n",
    "    bounds=p_bounds,\n",
    "    param_types=p_types,\n",
    "    shrink=0.5,\n",
    "    max_iters=200\n",
    ")\n",
    "\n",
    "rmse_best = best_result[0]\n",
    "k_best, beta_best, rho_best, p_best = best_result[1]\n",
    "avg_new_I, avg_S, avg_I, avg_R, avg_V = best_result[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19629035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== BEST PARAMETERS (global minimum found) ===\")\n",
    "print(f\"k = {k_best}\")\n",
    "print(f\"beta = {beta_best}\")\n",
    "print(f\"rho = {rho_best}\")\n",
    "print(f\"p = {p_best}\")\n",
    "print(f\"RMSE = {rmse_best:.3f}\")\n",
    "rmse, avg_new_I_sim, avg_S_sim, avg_I_sim, avg_R_sim, avg_V_sim = simulate(\n",
    "     k_best, beta_best, rho_best, p_best, graph_generation_func=generate_small_world_graph, n_simulations=99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa763949",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Simulation results vs true data\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, WEEKS + 1), avg_new_I_sim[1:], marker='o', linestyle='-', label='Model: avg_new_I_100_sim')\n",
    "plt.plot(range(1, WEEKS + 1), I0[1:],        marker='s', linestyle='--', label='True: I0')\n",
    "plt.plot(range(1, WEEKS + 1), avg_new_I[1:], marker='o', linestyle='-', label='Model: avg_new_I_best')\n",
    "plt.title(f'Weekly newly infected: model vs true (k={k_best}, beta={beta_best:.3f}, rho={rho_best:.3f}), p={p_best:.3f})')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Newly infected individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# S, I, R, V totals\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(0, WEEKS + 1), avg_S, marker='o', label='Susceptible (S)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_I, marker='o', label='Infected (I)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_R, marker='o', label='Recovered (R)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_V, marker='o', label='Vaccinated (V)')\n",
    "plt.title('100 simulations over best param configuration average totals each week: S, I, R, V')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceda951",
   "metadata": {},
   "source": [
    "#### Holme-Kim params estimation and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_init = [10,  0.3, 0.6, 0.1]          # k0, beta0, rho0, p\n",
    "steps_init  = [3,   0.1, 0.1, 0.01]         # dk, db, dr\n",
    "min_steps   = [1,   0.01, 0.01, 0.005]      # min_dk, min_db, min_dr\n",
    "p_types     = [int, float, float, float]    # types\n",
    "p_bounds    = [\n",
    "    # Bounds: k >= 2, 0 <= beta <= 1, 0 <= rho <= 1\n",
    "    (2, None), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0)\n",
    "]\n",
    "\n",
    "def simulate_holme_kim(k, beta, rho, p):\n",
    "    return simulate(k, beta, rho, p, graph_generation_func=generate_holme_kim, n_simulations=N)\n",
    "\n",
    "best_result = fit_generic_adaptive_steps(\n",
    "    simulate_func=simulate_holme_kim,\n",
    "    initial_params=params_init,\n",
    "    initial_steps=steps_init,\n",
    "    min_steps=min_steps,\n",
    "    bounds=p_bounds,\n",
    "    param_types=p_types,\n",
    "    shrink=0.5,\n",
    "    max_iters=200\n",
    ")\n",
    "\n",
    "rmse_best = best_result[0]\n",
    "k_best, beta_best, rho_best, p_best = best_result[1]\n",
    "avg_new_I, avg_S, avg_I, avg_R, avg_V = best_result[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== BEST PARAMETERS (global minimum found) ===\")\n",
    "print(f\"k = {k_best}\")\n",
    "print(f\"beta = {beta_best}\")\n",
    "print(f\"rho = {rho_best}\")\n",
    "print(f\"p = {p_best}\")\n",
    "print(f\"RMSE = {rmse_best:.4f}\")\n",
    "\n",
    "rmse, avg_new_I_sim, avg_S_sim, avg_I_sim, avg_R_sim, avg_V_sim = simulate(\n",
    "     k_best, beta_best, rho_best, p_best, graph_generation_func=generate_holme_kim, n_simulations=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Simulation results vs true data\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, WEEKS + 1), avg_new_I_sim[1:], marker='o', linestyle='-', label='Model: avg_new_I_100_sim')\n",
    "plt.plot(range(1, WEEKS + 1), I0[1:],        marker='s', linestyle='--', label='True: I0')\n",
    "plt.plot(range(1, WEEKS + 1), avg_new_I[1:], marker='o', linestyle='-', label='Model: avg_new_I_best')\n",
    "plt.title(f'Weekly newly infected: model vs true (k={k_best}, beta={beta_best:.3f}, rho={rho_best:.3f}), p={p_best:.3f})')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Newly infected individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# S, I, R, V totals\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(0, WEEKS + 1), avg_S, marker='o', label='Susceptible (S)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_I, marker='o', label='Infected (I)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_R, marker='o', label='Recovered (R)')\n",
    "plt.plot(range(0, WEEKS + 1), avg_V, marker='o', label='Vaccinated (V)')\n",
    "plt.title('100 simulation over best params config average totals each week: S, I, R, V')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of individuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713190c6",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce91bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PLAYERS = 3\n",
    "ACTIONS = [1, -1]\n",
    "N_ACTIONS = len(ACTIONS)\n",
    "N_STEPS = 100\n",
    "N_SIMULATIONS = 10000\n",
    "BURN_IN = 10\n",
    "\n",
    "n_states_tuple = tuple(N_ACTIONS for _ in range(N_PLAYERS))\n",
    "n_config = N_ACTIONS ** N_PLAYERS\n",
    "BETA = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility(player_idx, config_tuple, n1):\n",
    "    u = 0\n",
    "    is_coordinator = player_idx < n1\n",
    "\n",
    "    for j in range(N_PLAYERS):\n",
    "        if j == player_idx: continue\n",
    "\n",
    "        if is_coordinator:\n",
    "            val = 0.5 * abs(config_tuple[player_idx] + config_tuple[j])\n",
    "        else:\n",
    "            val = 0.5 * abs(config_tuple[player_idx] - config_tuple[j])\n",
    "        u += val\n",
    "    return u\n",
    "\n",
    "\n",
    "def build_Lambda(n1):\n",
    "    Lambda = sp.sparse.lil_matrix((n_config, n_config))\n",
    "\n",
    "    for x_id in range(n_config):\n",
    "        x_indices = np.unravel_index(x_id, shape=n_states_tuple) # Converts numeric index in a tuple of indices\n",
    "        x_indices = np.array(x_indices)\n",
    "\n",
    "        # Mapping indices -> real values\n",
    "        current_config = [ACTIONS[k] for k in x_indices]\n",
    "\n",
    "        for player in range(N_PLAYERS):\n",
    "            utilities = []\n",
    "            for action_idx, action_val in enumerate(ACTIONS):\n",
    "                y_config = list(current_config)\n",
    "                y_config[player] = action_val\n",
    "                utilities.append(get_utility(player, y_config, n1))\n",
    "\n",
    "            # Best Response Set\n",
    "            max_u = max(utilities)\n",
    "            br_indices = [idx for idx, u in enumerate(utilities) if u == max_u]\n",
    "\n",
    "            # Compute choice probability\n",
    "            prob_choice = 1.0 / len(br_indices)\n",
    "\n",
    "            for action_idx in br_indices:\n",
    "                if action_idx == x_indices[player]:\n",
    "                    continue\n",
    "\n",
    "                y_indices = np.copy(x_indices)\n",
    "                y_indices[player] = action_idx\n",
    "                y_id = np.ravel_multi_index(tuple(y_indices), dims=n_states_tuple)\n",
    "\n",
    "                Lambda[x_id, y_id] += 1.0 * prob_choice\n",
    "\n",
    "    return Lambda\n",
    "\n",
    "\n",
    "# Using the 2nd approach of CTMC\n",
    "def simulation(P, w, start_id, N_STEPS=100):\n",
    "    n_states = P.shape[0]\n",
    "\n",
    "    states = np.zeros(N_STEPS, dtype=int)\n",
    "    transition_times = np.zeros(N_STEPS)\n",
    "\n",
    "    states[0] = start_id\n",
    "    current_id = start_id\n",
    "    current_time = 0.0\n",
    "\n",
    "    # simulation cycle\n",
    "    for i in range(1, N_STEPS):\n",
    "        t_next = -np.log(np.random.rand()) / w[current_id]\n",
    "\n",
    "        current_time += t_next\n",
    "        transition_times[i] = current_time\n",
    "\n",
    "        probs = P[current_id, :]\n",
    "        next_id = np.random.choice(n_states, p=probs)\n",
    "        states[i] = next_id\n",
    "        current_id = next_id\n",
    "\n",
    "    return transition_times, states\n",
    "\n",
    "# For better visualization\n",
    "def get_label(x_id):\n",
    "        idx = np.unravel_index(x_id, n_states_tuple)\n",
    "        return \"\".join([\"+\" if ACTIONS[k]==1 else \"-\" for k in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9746514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver(n1, title_suffix):\n",
    "    print(f\"{title_suffix} (n1={n1})\")\n",
    "\n",
    "    start_indices = (0, 1, 0) # initial state (1, -1, 1)\n",
    "    start_id = np.ravel_multi_index(start_indices, dims=n_states_tuple)\n",
    "\n",
    "    Lambda = build_Lambda(n1)\n",
    "\n",
    "    Lambda_dense = Lambda.toarray()\n",
    "    n_states = Lambda_dense.shape[0]\n",
    "\n",
    "    w = np.sum(Lambda_dense, axis=1)\n",
    "\n",
    "    for i in range(n_states):\n",
    "        # add selfloop if a configuration is a sink, otherwise D is not well defined\n",
    "        if w[i] == 0: # absorbing state, no changes\n",
    "            w[i] = 1.0\n",
    "            Lambda_dense[i, i] = 1.0\n",
    "\n",
    "    D = np.diag(w)\n",
    "    P = np.linalg.inv(D) @ Lambda_dense\n",
    "\n",
    "    \n",
    "    # Transition graph\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            if i == j:\n",
    "                continue\n",
    "            prob = P[i, j]\n",
    "            if prob > 0.001:\n",
    "                G.add_edge(get_label(i), get_label(j), weight=prob)\n",
    "\n",
    "\n",
    "    # Compute probability distribution\n",
    "    total_time_in_state = defaultdict(float)\n",
    "    total_valid_time = 0.0\n",
    "    for i in range(N_SIMULATIONS):\n",
    "        times, traj = simulation(P, w, start_id, N_STEPS)\n",
    "        for k in range(len(traj) - 1):\n",
    "            if k < BURN_IN: \n",
    "                continue # Skip the initial transition\n",
    "\n",
    "            state = traj[k]\n",
    "            duration = times[k+1] - times[k]\n",
    "\n",
    "            total_time_in_state[state] += duration\n",
    "            total_valid_time += duration\n",
    "\n",
    "    results = {}\n",
    "    for state_id, time_spent in total_time_in_state.items():\n",
    "        if time_spent > 0:\n",
    "            results[get_label(state_id)] = time_spent / total_valid_time\n",
    "\n",
    "    sorted_labels = sorted(results.keys())\n",
    "    sorted_probs = [results[lbl] for lbl in sorted_labels]\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    for lbl, prob in zip(sorted_labels, sorted_probs):\n",
    "        if prob > 1e-4:\n",
    "            print(f\"  State {lbl}: {prob:.4f}\")\n",
    "\n",
    "\n",
    "    # Simulation for plotting\n",
    "    times, traj = simulation(P, w, start_id, N_STEPS)\n",
    "\n",
    "\n",
    "    # Plot simulation\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.step(times, traj, where='post', color='blue', marker='o', markersize=4, linewidth=1.5)\n",
    "    plt.yticks(range(n_config), [get_label(i) for i in range(n_config)])\n",
    "    plt.title(f\"Traiettoria (Sparse Matrix)\\n{title_suffix}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot transition graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G, seed=42, k=1.5)\n",
    "    nx.draw_networkx(G, pos, node_color='lightgray', node_size=1500, edgecolors='black')\n",
    "    edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
    "    nx.draw_networkx_edges(G, pos, arrowstyle='-|>', arrowsize=15, edge_color='gray')\n",
    "\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        G, pos, \n",
    "        edge_labels=edge_labels, \n",
    "        font_size=8, \n",
    "        label_pos=0.6,\n",
    "        bbox=dict(facecolor='white', edgecolor='none', alpha=0.7)\n",
    "    )\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Transition Graph\\n{title_suffix}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f15596",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver(3, \"Pure cooridination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver(0, \"Anti-Coordination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4912de3",
   "metadata": {},
   "source": [
    "### Noisy Dynamics Best Response\n",
    "\n",
    "with $\\beta \\rightarrow \\infty$ (vanishing noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all states\n",
    "ALL_STATES = list(itertools.product(ACTIONS, repeat=N_PLAYERS))\n",
    "\n",
    "def build_Lambda_noisy(n1, beta):\n",
    "    Lambda = sp.sparse.lil_matrix((n_config, n_config))\n",
    "\n",
    "    for x_id in range(n_config):\n",
    "        x_indices = np.unravel_index(x_id, shape=n_states_tuple)\n",
    "        x_indices = np.array(x_indices)\n",
    "\n",
    "        current_config = [ACTIONS[i] for i in x_indices]\n",
    "\n",
    "        for player in range(N_PLAYERS):\n",
    "            utilities = np.zeros(N_ACTIONS)\n",
    "            for action_idx, action_val in enumerate(ACTIONS):\n",
    "                y_config = list(current_config)\n",
    "                y_config[player] = action_val\n",
    "                utilities[action_idx] = get_utility(player, y_config, n1)\n",
    "\n",
    "            # exp(beta * U)\n",
    "            exp_utilities = np.exp(beta * utilities)\n",
    "            sum_exp = np.sum(exp_utilities)\n",
    "\n",
    "            for action_idx, action_val in enumerate(ACTIONS):\n",
    "                if action_idx == x_indices[player]:\n",
    "                    continue\n",
    "\n",
    "                y_indices = np.copy(x_indices)\n",
    "                y_indices[player] = action_idx\n",
    "                y_id = np.ravel_multi_index(tuple(y_indices), dims=n_states_tuple)\n",
    "\n",
    "                Lambda[x_id, y_id] += exp_utilities[action_idx] / sum_exp\n",
    "\n",
    "    return Lambda\n",
    "\n",
    "\n",
    "def noisy_solver(n1, title_suffix):\n",
    "    print(f\"{title_suffix} (n1={n1})\")\n",
    "\n",
    "    start_indices = (0, 1, 0) # initial state (1, -1, 1)\n",
    "    start_id = np.ravel_multi_index(start_indices, dims=n_states_tuple)\n",
    "\n",
    "    Lambda = build_Lambda_noisy(n1, BETA)\n",
    "    Lambda_dense = Lambda.toarray()\n",
    "    n_states = Lambda_dense.shape[0]\n",
    "\n",
    "    w = np.sum(Lambda_dense, axis=1)\n",
    "\n",
    "    for i in range(n_states):\n",
    "        # add selfloop if a configuration is a sink, otherwise D is not well defined\n",
    "        if w[i] == 0: # absorbing state, no changes\n",
    "            w[i] = 1.0\n",
    "            Lambda_dense[i, i] = 1.0\n",
    "\n",
    "    D = np.diag(w)\n",
    "    P = np.linalg.inv(D) @ Lambda_dense\n",
    "\n",
    "    total_time_in_state = defaultdict(float)\n",
    "    total_valid_time = 0.0\n",
    "    for i in range(N_SIMULATIONS):\n",
    "        times, traj = simulation(P, w, start_id, N_STEPS)\n",
    "        for k in range(len(traj) - 1):\n",
    "            if k < BURN_IN: \n",
    "                continue\n",
    "\n",
    "            state = traj[k]\n",
    "            duration = times[k+1] - times[k]\n",
    "\n",
    "            total_time_in_state[state] += duration\n",
    "            total_valid_time += duration\n",
    "\n",
    "    results = {}\n",
    "    for state_id, time_spent in total_time_in_state.items():\n",
    "        if time_spent > 0:\n",
    "            results[get_label(state_id)] = time_spent / total_valid_time\n",
    "\n",
    "    sorted_labels = sorted(results.keys())\n",
    "    sorted_probs = [results[lbl] for lbl in sorted_labels]\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    for lbl, prob in zip(sorted_labels, sorted_probs):\n",
    "        if prob > 1e-4:\n",
    "            print(f\"State {lbl}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_solver(3, \"Pure Coordination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864db936",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_solver(0, \"Pure Anti-Coordination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd50ce",
   "metadata": {},
   "source": [
    "with theory using:\n",
    "\n",
    "$$\n",
    "\\lim_{\\beta \\to \\infty} \\lim_{t \\to \\infty} P(X(t) = x) = \\lim_{\\beta \\to \\infty} \\pi_x = \n",
    "\\begin{cases} \n",
    "\\frac{1}{|\\argmax \\Phi|} & \\text{if } x \\in \\argmax \\Phi \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92bdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_and_states(n1):\n",
    "    states_data = []\n",
    "\n",
    "    # all possible states\n",
    "    for x_id in range(n_config):\n",
    "        x_indices = np.unravel_index(x_id, shape=n_states_tuple)\n",
    "        config = [ACTIONS[k] for k in x_indices]\n",
    "\n",
    "        total_utility = sum(get_utility(i, config, n1) for i in range(N_PLAYERS))\n",
    "\n",
    "        potential = 0.5 * total_utility # because each link is counted twice\n",
    "\n",
    "        label = \"\".join([\"+\" if c==1 else \"-\" for c in config])\n",
    "        states_data.append({'id': x_id, 'label': label, 'potential': potential})\n",
    "\n",
    "    return states_data\n",
    "\n",
    "\n",
    "def verify_theoretical_limit(n1):\n",
    "    states_data = get_potential_and_states(n1)\n",
    "\n",
    "    max_pot = max(s['potential'] for s in states_data)\n",
    "\n",
    "    max_states = [s for s in states_data if np.isclose(s['potential'], max_pot)]\n",
    "\n",
    "    prob_theoretical = 1.0 / len(max_states)\n",
    "\n",
    "    print(f\"Max potential: {max_pot}\")\n",
    "    print(f\"State at max potential: {len(max_states)}\")\n",
    "    print(f\"Theoretical probability: {prob_theoretical:.4f} on\")\n",
    "    for s in max_states:\n",
    "        print(f\"   * {s['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdde72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_theoretical_limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67998af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_theoretical_limit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5007d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
